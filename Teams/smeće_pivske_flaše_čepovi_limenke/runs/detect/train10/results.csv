                  epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                0.69058,                 0.9175,                0.94768,                0.89526,                0.89268,                0.90946,                0.77038,                0.66657,                0.89689,                0.87037,             0.00046551,             0.00046551,             0.00046551
                      2,                0.73241,                 1.0365,                0.94366,                0.89561,                0.84965,                0.89555,                0.71636,                 0.7687,                0.98936,                0.93039,              0.0008486,              0.0008486,              0.0008486
                      3,                 0.8413,                 1.0753,                0.99535,                 0.7831,                0.82658,                0.84907,                0.67634,                0.81268,                 1.1189,                0.95084,              0.0011374,              0.0011374,              0.0011374
                      4,                0.80268,                0.98743,                0.98144,                0.88031,                0.83981,                0.89601,                0.71094,                0.76449,                0.89515,                0.92532,              0.0010046,              0.0010046,              0.0010046
                      5,                0.77594,                0.93189,                0.98176,                 0.8804,                0.85108,                0.89977,                0.71321,                0.78557,                0.84786,                  0.941,             0.00086312,             0.00086312,             0.00086312
                      6,                0.76004,                0.87885,                0.96497,                0.88973,                0.87013,                0.90429,                0.74738,                0.66883,                0.77932,                0.88265,             0.00072164,             0.00072164,             0.00072164
                      7,                0.70926,                 0.8242,                0.94623,                0.88572,                0.87751,                0.90466,                0.74336,                0.69195,                0.74041,                 0.8901,             0.00058017,             0.00058017,             0.00058017
                      8,                 0.7046,                0.79315,                0.95456,                0.90059,                0.88759,                0.91456,                0.76977,                0.66734,                0.69107,                0.88465,              0.0004387,              0.0004387,              0.0004387
                      9,                0.67208,                0.73451,                0.92992,                0.90779,                0.90648,                0.91054,                0.78137,                0.61731,                0.66496,                0.85824,             0.00029723,             0.00029723,             0.00029723
                     10,                0.63028,                0.70558,                0.91642,                0.91635,                0.90922,                0.91859,                0.80413,                0.56207,                0.60662,                0.84868,             0.00015576,             0.00015576,             0.00015576
